{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45df7414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ed88de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4086fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_API_KEY']=os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT']=os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ['LANGCHAIN_TRACING_V2']=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63776d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation-p/anaconda3/envs/conda-env-3-12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b9c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOllama(model=\"gemma3:4b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c3df455",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"Hello, tell me a about NVIDIA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbb8ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=llm.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b86edb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Okay, let's dive into NVIDIA – they're a *huge* player in the tech world, and their influence is growing rapidly. Here’s a breakdown of what you need to know:\\n\\n**1. What NVIDIA Does - Core Business:**\\n\\n* **Graphics Processing Units (GPUs):** This is NVIDIA's bread and butter. They design and manufacture GPUs, which are specialized processors that excel at handling massively parallel computations – think graphics rendering, but also much, much more.\\n* **AI and Data Center Solutions:**  This is *now* NVIDIA’s biggest growth area. They're dominating the market for hardware and software designed for artificial intelligence (AI), deep learning, and high-performance computing (HPC).  Their data center GPUs are used for training and running AI models.\\n* **Gaming:** NVIDIA is a dominant force in the PC gaming market with their GeForce RTX series of GPUs, renowned for their high performance and features like ray tracing and DLSS (Deep Learning Super Sampling).\\n\\n\\n**2. Key Technologies & Products:**\\n\\n* **CUDA:** NVIDIA's proprietary parallel computing platform and programming model. It’s hugely important for developers wanting to take advantage of the power of NVIDIA GPUs for tasks beyond just graphics.  It allows programmers to write code that runs efficiently on NVIDIA hardware.\\n* **GeForce RTX Series:** Their flagship consumer GPUs, offering the best graphics performance and features for gamers.\\n* **Quadro Series:** Professional GPUs designed for workstations used by designers, engineers, and other professionals.\\n* **Tesla & Data Center GPUs:**  A range of GPUs specifically built for data centers, used for AI training, inference, and HPC. (Examples: A100, H100)\\n* **Jetson Series:** Small, embedded computers based on NVIDIA GPUs, designed for robotics, drones, and edge computing.\\n* **Omniverse:** A platform for 3D design collaboration and simulation.\\n\\n**3. History & Background:**\\n\\n* **Founded:** 1993 by Jensen Huang, Chris Malachowsky, and Curtis Priem. Initially focused on accelerating 3D graphics.\\n* **Early Success:**  NVIDIA quickly gained prominence by developing the first commercially successful GPU-based graphics cards.\\n* **Evolution:** They’ve consistently innovated, moving beyond just graphics to embrace AI, data centers, and automotive applications.\\n\\n**4. Market Position & Dominance:**\\n\\n* **GPU Market Share:** NVIDIA holds a *significant* market share in the GPU market, often around 80-90% in the high-end gaming and professional segments.  They are the clear market leader.\\n* **AI Leadership:** They are considered a leader in the AI hardware space, with their data center GPUs driving much of the innovation in the field.\\n* **Competition:** NVIDIA's main competitors include:\\n    * **AMD:** A major rival in the GPU market, offering competing products.\\n    * **Intel:** Increasingly entering the discrete GPU market.\\n    * **Google & Amazon:**  Developing their own AI accelerators and cloud computing solutions.\\n\\n\\n\\n**5. Recent Developments & Trends:**\\n\\n* **AI Boom:** NVIDIA's stock price has skyrocketed in recent years due to the explosive growth in AI.  The demand for their GPUs for AI training is enormous.\\n* **H100 GPU:** Their latest flagship data center GPU, the H100, is specifically designed for large language models and other demanding AI workloads.\\n* **Expansion into Automotive:** NVIDIA is developing autonomous driving systems and is a key player in the automotive industry.\\n* **Metaverse & Simulation:**  They're investing in technologies for the metaverse and simulation, utilizing their Omniverse platform.\\n\\n\\n\\n**Resources for More Information:**\\n\\n* **NVIDIA Website:** [https://www.nvidia.com/](https://www.nvidia.com/)\\n* **Wikipedia - NVIDIA:** [https://en.wikipedia.org/wiki/NVIDIA](https://en.wikipedia.org/wiki/NVIDIA)\\n* **Forbes - NVIDIA:** [https://www.forbes.com/nvidia/](https://www.forbes.com/nvidia/)\\n\\n---\\n\\n**To help me give you even more tailored information, could you tell me:**\\n\\n*   What specifically are you interested in learning about NVIDIA? (e.g., their AI business, gaming GPUs, their history, their stock price, etc.)\", additional_kwargs={}, response_metadata={'model': 'gemma3:4b', 'created_at': '2026-02-15T18:08:50.341532541Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11141823386, 'load_duration': 155102281, 'prompt_eval_count': 16, 'prompt_eval_duration': 35704434, 'eval_count': 923, 'eval_duration': 10545465367, 'logprobs': None, 'model_name': 'gemma3:4b', 'model_provider': 'ollama'}, id='lc_run--019c627d-8515-77a3-9199-fa52dfc03f2e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 16, 'output_tokens': 923, 'total_tokens': 939})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b8865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a expert ML engineer. Provide me answers based on the question.\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "081fa73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llm\n",
    "response=chain.invoke({\"input\":\"Can you tell me about langchain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "906f2bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's dive into LangChain. As an ML Engineer, I can tell you it's become a *hugely* influential framework for building applications powered by large language models (LLMs) like GPT-3, GPT-4, PaLM, and others. Here's a breakdown, covering key aspects and why it’s so significant:\n",
      "\n",
      "**What is LangChain?**\n",
      "\n",
      "At its core, LangChain is a framework designed to simplify the process of developing applications that leverage LLMs. It’s not a single model or a specific algorithm; instead, it’s a collection of tools, components, and abstractions that make it easier to:\n",
      "\n",
      "* **Connect to LLMs:**  LangChain provides standardized interfaces to interact with various LLMs, regardless of the underlying provider (OpenAI, Cohere, Hugging Face, etc.).\n",
      "* **Chain Together LLM Calls:** This is where it gets powerful. LangChain allows you to create sequences of calls to LLMs, combined with other tools and data sources, to create more complex and sophisticated applications. Think of it as building pipelines with LLMs at each step.\n",
      "* **Manage Data:**  LLMs are only as good as the data they’re trained on. LangChain offers components for loading, transforming, and indexing your own data, allowing you to ground the LLM’s responses in relevant context.\n",
      "\n",
      "\n",
      "**Key Components & Concepts:**\n",
      "\n",
      "* **Models:**  This is the foundation – the interface to your chosen LLM. LangChain provides adapters for different LLM providers.\n",
      "* **Prompts:**  Crafting the right prompts is *crucial* for getting the desired output from an LLM. LangChain offers prompt templates and management tools to help you design effective prompts.\n",
      "* **Chains:** The core of LangChain. Chains are sequences of calls to LLMs or other utilities. There are different types:\n",
      "    * **LLMChain:** The most basic chain, simply feeding a prompt to an LLM.\n",
      "    * **Sequential Chains:** Allows you to chain multiple LLM calls together.\n",
      "    * **Router Chains:**  Dynamically select the next component in a chain based on the input.\n",
      "* **Indexes:**  LangChain provides ways to structure and query your data – crucial for Retrieval-Augmented Generation (RAG).\n",
      "* **Memory:** LLMs are stateless by default. Memory allows you to maintain context across multiple interactions, enabling conversational applications.  There are various memory types (e.g., conversation buffer, vectorstore memory).\n",
      "* **Agents:** Agents are perhaps the most fascinating aspect. They use LLMs to *decide* which actions to take – this could be calling another tool, searching the web, or even generating code.  They're essentially giving the LLM agency.\n",
      "* **Callbacks:**  Allow you to track and log the progress of your chains and agents, aiding in debugging and monitoring.\n",
      "\n",
      "**Why is LangChain so Popular?**\n",
      "\n",
      "* **Abstraction:** It drastically reduces the boilerplate code needed to work with LLMs. You don’t have to implement everything from scratch.\n",
      "* **Rapid Prototyping:**  The modular design and readily available components accelerate development.\n",
      "* **Community & Ecosystem:**  LangChain has a huge and active community, offering support, tutorials, and integrations.\n",
      "* **RAG (Retrieval-Augmented Generation):**  LangChain is *particularly* strong in facilitating RAG, which significantly improves the accuracy and relevance of LLM responses by grounding them in external knowledge.\n",
      "\n",
      "\n",
      "\n",
      "**Example Use Cases:**\n",
      "\n",
      "* **Chatbots:**  Conversational AI applications that can answer questions, provide support, and engage in dialogue.\n",
      "* **Question Answering Systems:**  Applications that can retrieve and synthesize information from documents.\n",
      "* **Data Analysis:**  Using LLMs to analyze data and generate reports.\n",
      "* **Code Generation:**  Generating code snippets based on natural language descriptions.\n",
      "* **Content Creation:**  Assisting with writing articles, blog posts, or other creative content.\n",
      "\n",
      "\n",
      "\n",
      "**Resources to Learn More:**\n",
      "\n",
      "* **Official LangChain Website:** [https://www.langchain.com/](https://www.langchain.com/)\n",
      "* **LangChain Documentation:** [https://python.langchain.com/](https://python.langchain.com/)\n",
      "* **LangChain Tutorials:** [https://python.langchain.com/docs/tutorials](https://python.langchain.com/docs/tutorials)\n",
      "\n",
      "---\n",
      "\n",
      "**To help me give you even more targeted information, could you tell me:**\n",
      "\n",
      "*   What's your current level of experience with LLMs and Python?\n",
      "*   What specific type of application are you interested in building with LangChain? (e.g., a chatbot, a question-answering system, etc.)\n"
     ]
    }
   ],
   "source": [
    "# string output parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about langchain?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f05ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4119eb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82717e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881d14ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env-3-12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
