{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45df7414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ed88de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4086fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_API_KEY']=os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT']=os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ['LANGCHAIN_TRACING_V2']=\"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63776d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation-p/anaconda3/envs/conda-env-3-12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b9c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOllama(model=\"gemma3:4b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c3df455",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"Hello, tell me a about NVIDIA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbb8ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=llm.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b86edb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Okay, let's dive into NVIDIA! They're a hugely influential company, and their story is fascinating. Here's a breakdown of everything you should know about them:\\n\\n**1. What NVIDIA Does – Core Business:**\\n\\nAt its core, NVIDIA specializes in **graphics processing units (GPUs)**. However, they've dramatically expanded beyond just gaming and graphics cards. Here's a breakdown of their key areas:\\n\\n* **Gaming:** This is where they started and remains a significant part of their business. Their GeForce RTX GPUs are renowned for delivering high-performance graphics in games.\\n* **Data Center (AI & HPC):** This is *now* NVIDIA's biggest growth area. They're leading the market for GPUs used in:\\n    * **Artificial Intelligence (AI):** Training complex AI models (like those powering chatbots and self-driving cars) demands massive computing power, which NVIDIA's GPUs provide.\\n    * **High-Performance Computing (HPC):** Scientific simulations, weather forecasting, drug discovery, and other computationally intensive tasks rely on NVIDIA's GPUs.\\n* **Professional Visualization:** NVIDIA's Quadro cards are used in professional applications like:\\n    * **CAD (Computer-Aided Design):** Architects, engineers, and designers use them for detailed 3D modeling and rendering.\\n    * **Digital Content Creation (DCC):**  Video editing, animation, and visual effects rely on NVIDIA's GPUs.\\n* **Automotive:** NVIDIA is a major player in the development of autonomous driving technology. Their Drive platform is designed to power self-driving cars.\\n* **Orin System:** NVIDIA is also developing the Orin System, a powerful processor designed for edge computing applications, including robotics, industrial automation, and smart cameras.\\n\\n\\n**2. History & Key Milestones:**\\n\\n* **1993:** Founded by Jensen Huang, Chris Malins, and Curtis Priem. Their initial goal was to create a 3D Labs division to develop a powerful graphics card.\\n* **1999:** Launched the GeForce 256, the first consumer GPU that challenged the dominance of 3Dfx.\\n* **2006:** Introduced CUDA – a parallel computing platform and programming model – which revolutionized GPU computing and allowed developers to harness the power of GPUs for general-purpose computing.  This was *huge* for NVIDIA.\\n* **2016:** Jensen Huang became CEO, ushering in a new era of strategic focus on data centers and AI.\\n* **Recent Years:** Exponential growth driven by the demand for AI-powered solutions.\\n\\n\\n**3. Key Technologies & Products:**\\n\\n* **GPUs (GeForce, RTX, Quadro):**  The foundation of their business.  The RTX series incorporates Ray Tracing technology, which simulates the way light behaves in the real world for incredibly realistic visuals.\\n* **CUDA:** Their parallel computing platform.\\n* **NVSwitch:** A technology that allows NVIDIA GPUs to be connected together to create massively parallel computing systems, particularly relevant for data centers.\\n* **Drive Platform:** For autonomous driving.\\n* **Omniverse:** A platform for 3D design collaboration.\\n\\n**4. Financials & Market Position:**\\n\\n* **Revenue:** NVIDIA is one of the most valuable companies in the world, consistently generating billions of dollars in revenue.\\n* **Market Leader:** They are the dominant player in the GPU market, particularly in the high-end gaming and data center segments.\\n* **Stock Symbol:** NVDA (traded on the NASDAQ)\\n\\n**5.  Controversies & Challenges:**\\n\\n* **Supply Chain Issues:** Like many tech companies, NVIDIA has faced significant supply chain disruptions, particularly regarding the availability of memory chips.\\n* **AI Ethics & Bias:** As their GPUs are used to train powerful AI models, concerns about potential bias and ethical implications are being raised.\\n* **Competition:**  AMD is a major competitor in the GPU market, and Intel is also increasing its efforts in the discrete GPU space.\\n\\n\\n\\n**Resources to Learn More:**\\n\\n* **NVIDIA Website:** [https://www.nvidia.com/](https://www.nvidia.com/)\\n* **Wikipedia - NVIDIA:** [https://en.wikipedia.org/wiki/NVIDIA](https://en.wikipedia.org/wiki/NVIDIA)\\n* **TechRadar - NVIDIA:** [https://www.techradar.com/nvidia](https://www.techradar.com/nvidia)\\n\\n---\\n\\n**To help me give you even more tailored information, could you tell me:**\\n\\n*   What specifically are you interested in learning about NVIDIA? (e.g., their gaming GPUs, their AI business, their history, a particular product?)\\n*   What's your level of technical knowledge? (e.g., are you a gamer, a student, a developer, or just generally curious?)\", additional_kwargs={}, response_metadata={'model': 'gemma3:4b', 'created_at': '2026-02-15T11:07:42.155100265Z', 'done': True, 'done_reason': 'stop', 'total_duration': 14399029766, 'load_duration': 1985569191, 'prompt_eval_count': 16, 'prompt_eval_duration': 30881119, 'eval_count': 1019, 'eval_duration': 11809757743, 'logprobs': None, 'model_name': 'gemma3:4b', 'model_provider': 'ollama'}, id='lc_run--019c60fb-e88a-79e0-b6b4-5d4860813d52-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 16, 'output_tokens': 1019, 'total_tokens': 1035})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b8865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a expert ML engineer. Provide me answers based on the question.\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "081fa73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llm\n",
    "response=chain.invoke({\"input\":\"Can you tell me about langchain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "906f2bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's dive into LangChain. As an ML engineer, I can tell you it's become a *hugely* important framework for building applications powered by Large Language Models (LLMs) like GPT-3, GPT-4, Claude, and others. Here's a breakdown, covering the key aspects:\n",
      "\n",
      "**What is LangChain?**\n",
      "\n",
      "At its core, LangChain is a framework designed to simplify the development of applications using LLMs. Think of it as a toolkit and a set of abstractions that streamline the process of connecting LLMs with other components – data sources, memory, tools, and more – to create truly intelligent and useful applications. \n",
      "\n",
      "**Why is it gaining so much traction?**\n",
      "\n",
      "* **Reduces Boilerplate:** Traditionally, using LLMs directly often involves a lot of manual coding to handle things like prompt engineering, data retrieval, conversation management, and integration with external systems. LangChain dramatically reduces this boilerplate, allowing you to focus on the *logic* of your application.\n",
      "* **Modular Design:** LangChain is built around concepts like “chains” – sequences of calls to LLMs and other components – and “agents” – which can autonomously decide which tool to use based on the context. This modularity makes it incredibly flexible and adaptable.\n",
      "* **Rapid Prototyping:**  The framework is designed for speed. You can quickly assemble and experiment with different combinations of components to test ideas and iterate rapidly.\n",
      "* **Large Community & Growing Ecosystem:** LangChain has a vibrant and active community, leading to constant updates, new integrations, and extensive documentation.\n",
      "\n",
      "\n",
      "**Key Components & Concepts:**\n",
      "\n",
      "Here's a breakdown of the core elements within LangChain:\n",
      "\n",
      "1. **LLM Models:**  LangChain provides interfaces and abstractions to interact with various LLMs. It doesn’t dictate *which* LLM you use; it just provides a consistent way to communicate with them. It supports OpenAI, Cohere, Hugging Face, and many more.\n",
      "\n",
      "2. **Prompts:** LangChain makes prompt engineering easier. It offers pre-built prompt templates and allows you to define custom prompts with variables. It handles things like formatting your input for the LLM.\n",
      "\n",
      "3. **Chains:** This is a central concept. Chains are sequences of calls to LLMs or other components.  Examples:\n",
      "   * **Simple Prompt Chain:** Just a sequence of prompts.\n",
      "   * **LLMChain:** Combines an LLM with a prompt template.\n",
      "   * **Conversational Chain:** Designed for multi-turn conversations, maintaining context between turns.\n",
      "\n",
      "4. **Indexes & Retrieval:** This is *critical* for building applications that need to access and use external knowledge. LangChain provides ways to:\n",
      "   * **Load Data:**  Load data from various sources (documents, PDFs, websites, databases).\n",
      "   * **Split Data:** Break down large documents into smaller chunks that fit the LLM’s context window.\n",
      "   * **Embeddings:** Convert text into numerical representations (vectors) that LLMs can understand and compare.\n",
      "   * **Vectorstores:** Store these embeddings and enable efficient similarity search (finding the most relevant chunks of text). Popular vectorstores include Chroma, Pinecone, and FAISS.\n",
      "\n",
      "5. **Memory:**  LLMs are stateless by default. To build conversational applications, you need memory to store and retrieve information from previous interactions. LangChain provides several memory types:\n",
      "   * **ConversationBufferMemory:** Stores the entire conversation history.\n",
      "   * **ConversationSummaryMemory:**  Summarizes the conversation over time.\n",
      "   * **VectorstoreMemory:** Uses embeddings and vectorstores to retrieve relevant conversation history.\n",
      "\n",
      "6. **Agents:** Agents use LLMs to decide *which* actions to take. They can:\n",
      "    * Use tools (e.g., search engine, calculator, database query).\n",
      "    * Chain together multiple tools to solve complex problems.\n",
      "    * React to the output of other tools to refine their actions.\n",
      "\n",
      "\n",
      "\n",
      "**Example Use Cases:**\n",
      "\n",
      "* **Chatbots:**  Building sophisticated conversational agents.\n",
      "* **Question Answering:**  Retrieving answers to questions from your own data.\n",
      "* **Document Summarization:**  Automatically summarizing lengthy documents.\n",
      "* **Code Generation:**  Generating code from natural language prompts.\n",
      "* **Data Analysis:**  Using LLMs to analyze and interpret data.\n",
      "\n",
      "\n",
      "\n",
      "**Resources to Learn More:**\n",
      "\n",
      "* **LangChain Website:** [https://www.langchain.com/](https://www.langchain.com/) – The official documentation and tutorials are excellent.\n",
      "* **LangChain Documentation:** [https://python.langchain.com/](https://python.langchain.com/) -  The core documentation.\n",
      "* **LangChain Examples:** [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain) - Explore the example code.\n",
      "\n",
      "---\n",
      "\n",
      "**To help me give you even more targeted information, could you tell me:**\n",
      "\n",
      "*   What are you specifically interested in learning about LangChain? (e.g., a particular use case, a specific component, or the overall architecture?)\n",
      "*   What’s your current level of experience with LLMs and Python?\n"
     ]
    }
   ],
   "source": [
    "# string output parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about langchain?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f05ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4119eb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82717e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881d14ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env-3-12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
