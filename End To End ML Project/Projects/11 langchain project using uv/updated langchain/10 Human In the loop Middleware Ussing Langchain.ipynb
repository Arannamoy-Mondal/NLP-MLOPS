{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25f5f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langchain.messages import HumanMessage\n",
    "from langgraph.types import Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21c5f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_email_tool(email_id:str)->str:\n",
    "    \"\"\"Mock funtion to read an email by it's ID\"\"\"\n",
    "    return f\"Email content for ID   :{email_id}\"\n",
    "\n",
    "def send_email_tool(recipient:str,  subject:str,body:str)->str:\n",
    "    \"\"\"Mock function to send an email\"\"\"\n",
    "    return f\"Email sent to {recipient} with subject '{subject}'\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5d5168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatOllama(model=\"llama3.1:8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac75b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=create_agent(model=model,checkpointer=InMemorySaver(),tools=[read_email_tool,send_email_tool],\n",
    "                   middleware=[HumanInTheLoopMiddleware(interrupt_on={\n",
    "                       \"send_email_tool\":{\n",
    "                           \"allowed_decisions\":[\"approve\",\"edit\",\"reject\"]\n",
    "                       },\n",
    "                       \"read_email_tool\":False\n",
    "                   })]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b45684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"thread_id\":\"test-approve\"}}\n",
    "result=agent.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Send mail to john@test.com with subject 'Hello' and body 'How are you?'\")]},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ffe55d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Send mail to john@test.com with subject 'Hello' and body 'How are you?'\", additional_kwargs={}, response_metadata={}, id='22464af6-744b-48f2-a863-e96e474ea879'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2026-02-16T11:58:20.633127753Z', 'done': True, 'done_reason': 'stop', 'total_duration': 703451326, 'load_duration': 103519781, 'prompt_eval_count': 219, 'prompt_eval_duration': 19198758, 'eval_count': 34, 'eval_duration': 552773371, 'logprobs': None, 'model_name': 'llama3.1:8b', 'model_provider': 'ollama'}, id='lc_run--019c6650-d718-7081-92a3-d413bc34518b-0', tool_calls=[{'name': 'send_email_tool', 'args': {'body': 'How are you?', 'subject': 'Hello', 'recipient': 'john@test.com'}, 'id': '99e49bca-4bb6-456c-a114-755aba8364df', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 219, 'output_tokens': 34, 'total_tokens': 253})],\n",
       " '__interrupt__': [Interrupt(value={'action_requests': [{'name': 'send_email_tool', 'args': {'body': 'How are you?', 'subject': 'Hello', 'recipient': 'john@test.com'}, 'description': \"Tool execution requires approval\\n\\nTool: send_email_tool\\nArgs: {'body': 'How are you?', 'subject': 'Hello', 'recipient': 'john@test.com'}\"}], 'review_configs': [{'action_name': 'send_email_tool', 'allowed_decisions': ['approve', 'edit', 'reject']}]}, id='34513736a8c3cfe2890c20e7e5f40bf2')]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8847fdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paused ! Approving... \n",
      "Result: The email has been successfully sent.\n"
     ]
    }
   ],
   "source": [
    "if \"__interrupt__\" in result:\n",
    "    print(\"Paused ! Approving... \")\n",
    "    result=agent.invoke(\n",
    "        Command(\n",
    "            resume={\n",
    "                \"decisions\":[\n",
    "                    {\"type\":\"approve\"}\n",
    "                ]\n",
    "            }\n",
    "        ),\n",
    "        config=config\n",
    "    )\n",
    "    print(f\"Result: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b9c56c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Send mail to john@test.com with subject 'Hello' and body 'How are you?'\", additional_kwargs={}, response_metadata={}, id='22464af6-744b-48f2-a863-e96e474ea879'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2026-02-16T11:58:20.633127753Z', 'done': True, 'done_reason': 'stop', 'total_duration': 703451326, 'load_duration': 103519781, 'prompt_eval_count': 219, 'prompt_eval_duration': 19198758, 'eval_count': 34, 'eval_duration': 552773371, 'logprobs': None, 'model_name': 'llama3.1:8b', 'model_provider': 'ollama'}, id='lc_run--019c6650-d718-7081-92a3-d413bc34518b-0', tool_calls=[{'name': 'send_email_tool', 'args': {'body': 'How are you?', 'subject': 'Hello', 'recipient': 'john@test.com'}, 'id': '99e49bca-4bb6-456c-a114-755aba8364df', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 219, 'output_tokens': 34, 'total_tokens': 253}),\n",
       "  ToolMessage(content=\"Email sent to john@test.com with subject 'Hello'\", name='send_email_tool', id='cf335559-b54c-4813-886f-3e6b644be518', tool_call_id='99e49bca-4bb6-456c-a114-755aba8364df'),\n",
       "  AIMessage(content='The email has been successfully sent.', additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2026-02-16T11:58:20.938958516Z', 'done': True, 'done_reason': 'stop', 'total_duration': 270300732, 'load_duration': 94137581, 'prompt_eval_count': 126, 'prompt_eval_duration': 49805292, 'eval_count': 8, 'eval_duration': 118362600, 'logprobs': None, 'model_name': 'llama3.1:8b', 'model_provider': 'ollama'}, id='lc_run--019c6650-d9fb-7922-b802-2431a9624931-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 126, 'output_tokens': 8, 'total_tokens': 134})]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335779b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env-3-12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
