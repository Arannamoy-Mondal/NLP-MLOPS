{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6fbb49b",
   "metadata": {},
   "source": [
    "#### Breakdown of a single neural network\n",
    "- X -> input\n",
    "- Wx -> Weights\n",
    "- bx -> bias\n",
    "- A  -> Activation function\n",
    "- Y -> Output\n",
    "\n",
    "Z =W1.X +b1\n",
    "\n",
    "Z' = A(Z)=W1.X+b1 , this node has an activation function\n",
    "\n",
    "Y= W2.Z' + b2, this node has no activation function\n",
    "\n",
    "- Loss functin:\n",
    "- Caculate Gradient Using back propagation\n",
    "- Optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f353b26e",
   "metadata": {},
   "source": [
    "### Components of pytorch\n",
    "- Base class for defining custom model is `torch.nn.Module`\n",
    "\n",
    "- Fully connected or dense layers `torch.nn.linear`\n",
    "\n",
    "- Activation function `torch.nn.ReLU`\n",
    "\n",
    "- Optimizer `torch.optim`\n",
    "\n",
    "- Loss function `torch.nn.CrossEntropyLoss`\n",
    "\n",
    "- Loads data in batch `torch.utils.data.DataLoader`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53767198",
   "metadata": {},
   "source": [
    "### Different way to create neural network\n",
    "\n",
    "1. Functional:  Flexible, harder to interpret \n",
    "2. Sequential: nn.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5657c91",
   "metadata": {},
   "source": [
    "### Building a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d36d825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c162e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## functional API\n",
    "\n",
    "class SimpleFunctionalNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(SimpleFunctionalNN,self).__init__()\n",
    "        self.fc1=nn.Linear(input_size,hidden_size)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.fc2=nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.fc1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca11f40",
   "metadata": {},
   "source": [
    "##### $$\\text{Input} (x) \\rightarrow \\text{Linear Layer 1} \\rightarrow \\text{ReLU} \\rightarrow \\text{Linear Layer 2} \\rightarrow \\text{Output}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90af69a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSequentialNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(SimpleSequentialNN,self).__init__()\n",
    "        self.network=nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d26170f",
   "metadata": {},
   "source": [
    "### Training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84bff687",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fun1=SimpleFunctionalNN(input_size=4,hidden_size=8,output_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad1fed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleFunctionalNN(\n",
      "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_fun1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5062d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(10,4) # 10 sample, 4 features\n",
    "y=torch.randint(0,3,(10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b175dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model_fun1.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df2b8910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1324, -1.5509,  1.0822,  0.1772],\n",
      "        [-0.6567, -0.1501,  0.3686, -0.3058],\n",
      "        [ 0.6421, -1.4473, -1.7801,  0.6947],\n",
      "        [-0.8051, -1.3499,  0.4628, -2.1399],\n",
      "        [-0.6539,  1.8843, -0.8330,  0.2325],\n",
      "        [-1.8670,  0.7673, -0.8022,  1.2982],\n",
      "        [-1.2615, -2.0563,  1.4194,  1.5699],\n",
      "        [-0.3929,  0.2931,  2.0558,  1.7942],\n",
      "        [-1.5048,  0.1026,  0.1779, -1.4346],\n",
      "        [ 1.6240,  1.6330, -1.2811, -1.5841]]) tensor([0, 1, 1, 1, 1, 2, 1, 0, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2c5b98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting cpu: 0\n",
      "Setting cpu: 1\n",
      "Setting cpu: 2\n",
      "Setting cpu: 3\n",
      "Setting cpu: 4\n",
      "Setting cpu: 5\n",
      "Setting cpu: 6\n",
      "Setting cpu: 7\n",
      "Setting cpu: 8\n",
      "Setting cpu: 9\n",
      "Setting cpu: 10\n",
      "Setting cpu: 11\n",
      "Setting cpu: 12\n",
      "Setting cpu: 13\n",
      "Setting cpu: 14\n",
      "Setting cpu: 15\n",
      "Setting cpu: 16\n",
      "Setting cpu: 17\n",
      "Setting cpu: 18\n",
      "Setting cpu: 19\n",
      "Setting cpu: 20\n",
      "Setting cpu: 21\n",
      "Setting cpu: 22\n",
      "Setting cpu: 23\n",
      "Setting cpu: 24\n",
      "Setting cpu: 25\n",
      "Setting cpu: 26\n",
      "Setting cpu: 27\n",
      "Setting cpu: 28\n",
      "Setting cpu: 29\n",
      "Setting cpu: 30\n",
      "Setting cpu: 31\n",
      "Epoch 10/4000, Loss: 0.0001\n",
      "Epoch 20/4000, Loss: 0.0001\n",
      "Epoch 30/4000, Loss: 0.0001\n",
      "Epoch 40/4000, Loss: 0.0001\n",
      "Epoch 50/4000, Loss: 0.0001\n",
      "Epoch 60/4000, Loss: 0.0001\n",
      "Epoch 70/4000, Loss: 0.0001\n",
      "Epoch 80/4000, Loss: 0.0001\n",
      "Epoch 90/4000, Loss: 0.0001\n",
      "Epoch 100/4000, Loss: 0.0001\n",
      "Epoch 110/4000, Loss: 0.0001\n",
      "Epoch 120/4000, Loss: 0.0001\n",
      "Epoch 130/4000, Loss: 0.0001\n",
      "Epoch 140/4000, Loss: 0.0001\n",
      "Epoch 150/4000, Loss: 0.0001\n",
      "Epoch 160/4000, Loss: 0.0001\n",
      "Epoch 170/4000, Loss: 0.0001\n",
      "Epoch 180/4000, Loss: 0.0001\n",
      "Epoch 190/4000, Loss: 0.0001\n",
      "Epoch 200/4000, Loss: 0.0001\n",
      "Epoch 210/4000, Loss: 0.0001\n",
      "Epoch 220/4000, Loss: 0.0001\n",
      "Epoch 230/4000, Loss: 0.0001\n",
      "Epoch 240/4000, Loss: 0.0001\n",
      "Epoch 250/4000, Loss: 0.0001\n",
      "Epoch 260/4000, Loss: 0.0001\n",
      "Epoch 270/4000, Loss: 0.0001\n",
      "Epoch 280/4000, Loss: 0.0001\n",
      "Epoch 290/4000, Loss: 0.0001\n",
      "Epoch 300/4000, Loss: 0.0001\n",
      "Epoch 310/4000, Loss: 0.0001\n",
      "Epoch 320/4000, Loss: 0.0001\n",
      "Epoch 330/4000, Loss: 0.0001\n",
      "Epoch 340/4000, Loss: 0.0001\n",
      "Epoch 350/4000, Loss: 0.0001\n",
      "Epoch 360/4000, Loss: 0.0001\n",
      "Epoch 370/4000, Loss: 0.0001\n",
      "Epoch 380/4000, Loss: 0.0001\n",
      "Epoch 390/4000, Loss: 0.0001\n",
      "Epoch 400/4000, Loss: 0.0001\n",
      "Epoch 410/4000, Loss: 0.0001\n",
      "Epoch 420/4000, Loss: 0.0001\n",
      "Epoch 430/4000, Loss: 0.0001\n",
      "Epoch 440/4000, Loss: 0.0001\n",
      "Epoch 450/4000, Loss: 0.0001\n",
      "Epoch 460/4000, Loss: 0.0001\n",
      "Epoch 470/4000, Loss: 0.0001\n",
      "Epoch 480/4000, Loss: 0.0001\n",
      "Epoch 490/4000, Loss: 0.0001\n",
      "Epoch 500/4000, Loss: 0.0001\n",
      "Epoch 510/4000, Loss: 0.0001\n",
      "Epoch 520/4000, Loss: 0.0001\n",
      "Epoch 530/4000, Loss: 0.0001\n",
      "Epoch 540/4000, Loss: 0.0001\n",
      "Epoch 550/4000, Loss: 0.0001\n",
      "Epoch 560/4000, Loss: 0.0001\n",
      "Epoch 570/4000, Loss: 0.0001\n",
      "Epoch 580/4000, Loss: 0.0001\n",
      "Epoch 590/4000, Loss: 0.0001\n",
      "Epoch 600/4000, Loss: 0.0001\n",
      "Epoch 610/4000, Loss: 0.0001\n",
      "Epoch 620/4000, Loss: 0.0001\n",
      "Epoch 630/4000, Loss: 0.0001\n",
      "Epoch 640/4000, Loss: 0.0001\n",
      "Epoch 650/4000, Loss: 0.0001\n",
      "Epoch 660/4000, Loss: 0.0001\n",
      "Epoch 670/4000, Loss: 0.0001\n",
      "Epoch 680/4000, Loss: 0.0001\n",
      "Epoch 690/4000, Loss: 0.0001\n",
      "Epoch 700/4000, Loss: 0.0001\n",
      "Epoch 710/4000, Loss: 0.0001\n",
      "Epoch 720/4000, Loss: 0.0001\n",
      "Epoch 730/4000, Loss: 0.0001\n",
      "Epoch 740/4000, Loss: 0.0001\n",
      "Epoch 750/4000, Loss: 0.0001\n",
      "Epoch 760/4000, Loss: 0.0001\n",
      "Epoch 770/4000, Loss: 0.0001\n",
      "Epoch 780/4000, Loss: 0.0001\n",
      "Epoch 790/4000, Loss: 0.0001\n",
      "Epoch 800/4000, Loss: 0.0001\n",
      "Epoch 810/4000, Loss: 0.0001\n",
      "Epoch 820/4000, Loss: 0.0001\n",
      "Epoch 830/4000, Loss: 0.0001\n",
      "Epoch 840/4000, Loss: 0.0001\n",
      "Epoch 850/4000, Loss: 0.0001\n",
      "Epoch 860/4000, Loss: 0.0001\n",
      "Epoch 870/4000, Loss: 0.0001\n",
      "Epoch 880/4000, Loss: 0.0001\n",
      "Epoch 890/4000, Loss: 0.0001\n",
      "Epoch 900/4000, Loss: 0.0001\n",
      "Epoch 910/4000, Loss: 0.0001\n",
      "Epoch 920/4000, Loss: 0.0001\n",
      "Epoch 930/4000, Loss: 0.0001\n",
      "Epoch 940/4000, Loss: 0.0001\n",
      "Epoch 950/4000, Loss: 0.0001\n",
      "Epoch 960/4000, Loss: 0.0001\n",
      "Epoch 970/4000, Loss: 0.0001\n",
      "Epoch 980/4000, Loss: 0.0001\n",
      "Epoch 990/4000, Loss: 0.0001\n",
      "Epoch 1000/4000, Loss: 0.0001\n",
      "Epoch 1010/4000, Loss: 0.0001\n",
      "Epoch 1020/4000, Loss: 0.0001\n",
      "Epoch 1030/4000, Loss: 0.0001\n",
      "Epoch 1040/4000, Loss: 0.0001\n",
      "Epoch 1050/4000, Loss: 0.0001\n",
      "Epoch 1060/4000, Loss: 0.0001\n",
      "Epoch 1070/4000, Loss: 0.0001\n",
      "Epoch 1080/4000, Loss: 0.0001\n",
      "Epoch 1090/4000, Loss: 0.0001\n",
      "Epoch 1100/4000, Loss: 0.0001\n",
      "Epoch 1110/4000, Loss: 0.0001\n",
      "Epoch 1120/4000, Loss: 0.0001\n",
      "Epoch 1130/4000, Loss: 0.0001\n",
      "Epoch 1140/4000, Loss: 0.0001\n",
      "Epoch 1150/4000, Loss: 0.0001\n",
      "Epoch 1160/4000, Loss: 0.0001\n",
      "Epoch 1170/4000, Loss: 0.0001\n",
      "Epoch 1180/4000, Loss: 0.0001\n",
      "Epoch 1190/4000, Loss: 0.0001\n",
      "Epoch 1200/4000, Loss: 0.0001\n",
      "Epoch 1210/4000, Loss: 0.0001\n",
      "Epoch 1220/4000, Loss: 0.0001\n",
      "Epoch 1230/4000, Loss: 0.0001\n",
      "Epoch 1240/4000, Loss: 0.0001\n",
      "Epoch 1250/4000, Loss: 0.0001\n",
      "Epoch 1260/4000, Loss: 0.0001\n",
      "Epoch 1270/4000, Loss: 0.0001\n",
      "Epoch 1280/4000, Loss: 0.0001\n",
      "Epoch 1290/4000, Loss: 0.0001\n",
      "Epoch 1300/4000, Loss: 0.0001\n",
      "Epoch 1310/4000, Loss: 0.0001\n",
      "Epoch 1320/4000, Loss: 0.0001\n",
      "Epoch 1330/4000, Loss: 0.0001\n",
      "Epoch 1340/4000, Loss: 0.0001\n",
      "Epoch 1350/4000, Loss: 0.0001\n",
      "Epoch 1360/4000, Loss: 0.0001\n",
      "Epoch 1370/4000, Loss: 0.0001\n",
      "Epoch 1380/4000, Loss: 0.0001\n",
      "Epoch 1390/4000, Loss: 0.0001\n",
      "Epoch 1400/4000, Loss: 0.0001\n",
      "Epoch 1410/4000, Loss: 0.0001\n",
      "Epoch 1420/4000, Loss: 0.0001\n",
      "Epoch 1430/4000, Loss: 0.0000\n",
      "Epoch 1440/4000, Loss: 0.0000\n",
      "Epoch 1450/4000, Loss: 0.0000\n",
      "Epoch 1460/4000, Loss: 0.0000\n",
      "Epoch 1470/4000, Loss: 0.0000\n",
      "Epoch 1480/4000, Loss: 0.0000\n",
      "Epoch 1490/4000, Loss: 0.0000\n",
      "Epoch 1500/4000, Loss: 0.0000\n",
      "Epoch 1510/4000, Loss: 0.0000\n",
      "Epoch 1520/4000, Loss: 0.0000\n",
      "Epoch 1530/4000, Loss: 0.0000\n",
      "Epoch 1540/4000, Loss: 0.0000\n",
      "Epoch 1550/4000, Loss: 0.0000\n",
      "Epoch 1560/4000, Loss: 0.0000\n",
      "Epoch 1570/4000, Loss: 0.0000\n",
      "Epoch 1580/4000, Loss: 0.0000\n",
      "Epoch 1590/4000, Loss: 0.0000\n",
      "Epoch 1600/4000, Loss: 0.0000\n",
      "Epoch 1610/4000, Loss: 0.0000\n",
      "Epoch 1620/4000, Loss: 0.0000\n",
      "Epoch 1630/4000, Loss: 0.0000\n",
      "Epoch 1640/4000, Loss: 0.0000\n",
      "Epoch 1650/4000, Loss: 0.0000\n",
      "Epoch 1660/4000, Loss: 0.0000\n",
      "Epoch 1670/4000, Loss: 0.0000\n",
      "Epoch 1680/4000, Loss: 0.0000\n",
      "Epoch 1690/4000, Loss: 0.0000\n",
      "Epoch 1700/4000, Loss: 0.0000\n",
      "Epoch 1710/4000, Loss: 0.0000\n",
      "Epoch 1720/4000, Loss: 0.0000\n",
      "Epoch 1730/4000, Loss: 0.0000\n",
      "Epoch 1740/4000, Loss: 0.0000\n",
      "Epoch 1750/4000, Loss: 0.0000\n",
      "Epoch 1760/4000, Loss: 0.0000\n",
      "Epoch 1770/4000, Loss: 0.0000\n",
      "Epoch 1780/4000, Loss: 0.0000\n",
      "Epoch 1790/4000, Loss: 0.0000\n",
      "Epoch 1800/4000, Loss: 0.0000\n",
      "Epoch 1810/4000, Loss: 0.0000\n",
      "Epoch 1820/4000, Loss: 0.0000\n",
      "Epoch 1830/4000, Loss: 0.0000\n",
      "Epoch 1840/4000, Loss: 0.0000\n",
      "Epoch 1850/4000, Loss: 0.0000\n",
      "Epoch 1860/4000, Loss: 0.0000\n",
      "Epoch 1870/4000, Loss: 0.0000\n",
      "Epoch 1880/4000, Loss: 0.0000\n",
      "Epoch 1890/4000, Loss: 0.0000\n",
      "Epoch 1900/4000, Loss: 0.0000\n",
      "Epoch 1910/4000, Loss: 0.0000\n",
      "Epoch 1920/4000, Loss: 0.0000\n",
      "Epoch 1930/4000, Loss: 0.0000\n",
      "Epoch 1940/4000, Loss: 0.0000\n",
      "Epoch 1950/4000, Loss: 0.0000\n",
      "Epoch 1960/4000, Loss: 0.0000\n",
      "Epoch 1970/4000, Loss: 0.0000\n",
      "Epoch 1980/4000, Loss: 0.0000\n",
      "Epoch 1990/4000, Loss: 0.0000\n",
      "Epoch 2000/4000, Loss: 0.0000\n",
      "Epoch 2010/4000, Loss: 0.0000\n",
      "Epoch 2020/4000, Loss: 0.0000\n",
      "Epoch 2030/4000, Loss: 0.0000\n",
      "Epoch 2040/4000, Loss: 0.0000\n",
      "Epoch 2050/4000, Loss: 0.0000\n",
      "Epoch 2060/4000, Loss: 0.0000\n",
      "Epoch 2070/4000, Loss: 0.0000\n",
      "Epoch 2080/4000, Loss: 0.0000\n",
      "Epoch 2090/4000, Loss: 0.0000\n",
      "Epoch 2100/4000, Loss: 0.0000\n",
      "Epoch 2110/4000, Loss: 0.0000\n",
      "Epoch 2120/4000, Loss: 0.0000\n",
      "Epoch 2130/4000, Loss: 0.0000\n",
      "Epoch 2140/4000, Loss: 0.0000\n",
      "Epoch 2150/4000, Loss: 0.0000\n",
      "Epoch 2160/4000, Loss: 0.0000\n",
      "Epoch 2170/4000, Loss: 0.0000\n",
      "Epoch 2180/4000, Loss: 0.0000\n",
      "Epoch 2190/4000, Loss: 0.0000\n",
      "Epoch 2200/4000, Loss: 0.0000\n",
      "Epoch 2210/4000, Loss: 0.0000\n",
      "Epoch 2220/4000, Loss: 0.0000\n",
      "Epoch 2230/4000, Loss: 0.0000\n",
      "Epoch 2240/4000, Loss: 0.0000\n",
      "Epoch 2250/4000, Loss: 0.0000\n",
      "Epoch 2260/4000, Loss: 0.0000\n",
      "Epoch 2270/4000, Loss: 0.0000\n",
      "Epoch 2280/4000, Loss: 0.0000\n",
      "Epoch 2290/4000, Loss: 0.0000\n",
      "Epoch 2300/4000, Loss: 0.0000\n",
      "Epoch 2310/4000, Loss: 0.0000\n",
      "Epoch 2320/4000, Loss: 0.0000\n",
      "Epoch 2330/4000, Loss: 0.0000\n",
      "Epoch 2340/4000, Loss: 0.0000\n",
      "Epoch 2350/4000, Loss: 0.0000\n",
      "Epoch 2360/4000, Loss: 0.0000\n",
      "Epoch 2370/4000, Loss: 0.0000\n",
      "Epoch 2380/4000, Loss: 0.0000\n",
      "Epoch 2390/4000, Loss: 0.0000\n",
      "Epoch 2400/4000, Loss: 0.0000\n",
      "Epoch 2410/4000, Loss: 0.0000\n",
      "Epoch 2420/4000, Loss: 0.0000\n",
      "Epoch 2430/4000, Loss: 0.0000\n",
      "Epoch 2440/4000, Loss: 0.0000\n",
      "Epoch 2450/4000, Loss: 0.0000\n",
      "Epoch 2460/4000, Loss: 0.0000\n",
      "Epoch 2470/4000, Loss: 0.0000\n",
      "Epoch 2480/4000, Loss: 0.0000\n",
      "Epoch 2490/4000, Loss: 0.0000\n",
      "Epoch 2500/4000, Loss: 0.0000\n",
      "Epoch 2510/4000, Loss: 0.0000\n",
      "Epoch 2520/4000, Loss: 0.0000\n",
      "Epoch 2530/4000, Loss: 0.0000\n",
      "Epoch 2540/4000, Loss: 0.0000\n",
      "Epoch 2550/4000, Loss: 0.0000\n",
      "Epoch 2560/4000, Loss: 0.0000\n",
      "Epoch 2570/4000, Loss: 0.0000\n",
      "Epoch 2580/4000, Loss: 0.0000\n",
      "Epoch 2590/4000, Loss: 0.0000\n",
      "Epoch 2600/4000, Loss: 0.0000\n",
      "Epoch 2610/4000, Loss: 0.0000\n",
      "Epoch 2620/4000, Loss: 0.0000\n",
      "Epoch 2630/4000, Loss: 0.0000\n",
      "Epoch 2640/4000, Loss: 0.0000\n",
      "Epoch 2650/4000, Loss: 0.0000\n",
      "Epoch 2660/4000, Loss: 0.0000\n",
      "Epoch 2670/4000, Loss: 0.0000\n",
      "Epoch 2680/4000, Loss: 0.0000\n",
      "Epoch 2690/4000, Loss: 0.0000\n",
      "Epoch 2700/4000, Loss: 0.0000\n",
      "Epoch 2710/4000, Loss: 0.0000\n",
      "Epoch 2720/4000, Loss: 0.0000\n",
      "Epoch 2730/4000, Loss: 0.0000\n",
      "Epoch 2740/4000, Loss: 0.0000\n",
      "Epoch 2750/4000, Loss: 0.0000\n",
      "Epoch 2760/4000, Loss: 0.0000\n",
      "Epoch 2770/4000, Loss: 0.0000\n",
      "Epoch 2780/4000, Loss: 0.0000\n",
      "Epoch 2790/4000, Loss: 0.0000\n",
      "Epoch 2800/4000, Loss: 0.0000\n",
      "Epoch 2810/4000, Loss: 0.0000\n",
      "Epoch 2820/4000, Loss: 0.0000\n",
      "Epoch 2830/4000, Loss: 0.0000\n",
      "Epoch 2840/4000, Loss: 0.0000\n",
      "Epoch 2850/4000, Loss: 0.0000\n",
      "Epoch 2860/4000, Loss: 0.0000\n",
      "Epoch 2870/4000, Loss: 0.0000\n",
      "Epoch 2880/4000, Loss: 0.0000\n",
      "Epoch 2890/4000, Loss: 0.0000\n",
      "Epoch 2900/4000, Loss: 0.0000\n",
      "Epoch 2910/4000, Loss: 0.0000\n",
      "Epoch 2920/4000, Loss: 0.0000\n",
      "Epoch 2930/4000, Loss: 0.0000\n",
      "Epoch 2940/4000, Loss: 0.0000\n",
      "Epoch 2950/4000, Loss: 0.0000\n",
      "Epoch 2960/4000, Loss: 0.0000\n",
      "Epoch 2970/4000, Loss: 0.0000\n",
      "Epoch 2980/4000, Loss: 0.0000\n",
      "Epoch 2990/4000, Loss: 0.0000\n",
      "Epoch 3000/4000, Loss: 0.0000\n",
      "Epoch 3010/4000, Loss: 0.0000\n",
      "Epoch 3020/4000, Loss: 0.0000\n",
      "Epoch 3030/4000, Loss: 0.0000\n",
      "Epoch 3040/4000, Loss: 0.0000\n",
      "Epoch 3050/4000, Loss: 0.0000\n",
      "Epoch 3060/4000, Loss: 0.0000\n",
      "Epoch 3070/4000, Loss: 0.0000\n",
      "Epoch 3080/4000, Loss: 0.0000\n",
      "Epoch 3090/4000, Loss: 0.0000\n",
      "Epoch 3100/4000, Loss: 0.0000\n",
      "Epoch 3110/4000, Loss: 0.0000\n",
      "Epoch 3120/4000, Loss: 0.0000\n",
      "Epoch 3130/4000, Loss: 0.0000\n",
      "Epoch 3140/4000, Loss: 0.0000\n",
      "Epoch 3150/4000, Loss: 0.0000\n",
      "Epoch 3160/4000, Loss: 0.0000\n",
      "Epoch 3170/4000, Loss: 0.0000\n",
      "Epoch 3180/4000, Loss: 0.0000\n",
      "Epoch 3190/4000, Loss: 0.0000\n",
      "Epoch 3200/4000, Loss: 0.0000\n",
      "Epoch 3210/4000, Loss: 0.0000\n",
      "Epoch 3220/4000, Loss: 0.0000\n",
      "Epoch 3230/4000, Loss: 0.0000\n",
      "Epoch 3240/4000, Loss: 0.0000\n",
      "Epoch 3250/4000, Loss: 0.0000\n",
      "Epoch 3260/4000, Loss: 0.0000\n",
      "Epoch 3270/4000, Loss: 0.0000\n",
      "Epoch 3280/4000, Loss: 0.0000\n",
      "Epoch 3290/4000, Loss: 0.0000\n",
      "Epoch 3300/4000, Loss: 0.0000\n",
      "Epoch 3310/4000, Loss: 0.0000\n",
      "Epoch 3320/4000, Loss: 0.0000\n",
      "Epoch 3330/4000, Loss: 0.0000\n",
      "Epoch 3340/4000, Loss: 0.0000\n",
      "Epoch 3350/4000, Loss: 0.0000\n",
      "Epoch 3360/4000, Loss: 0.0000\n",
      "Epoch 3370/4000, Loss: 0.0000\n",
      "Epoch 3380/4000, Loss: 0.0000\n",
      "Epoch 3390/4000, Loss: 0.0000\n",
      "Epoch 3400/4000, Loss: 0.0000\n",
      "Epoch 3410/4000, Loss: 0.0000\n",
      "Epoch 3420/4000, Loss: 0.0000\n",
      "Epoch 3430/4000, Loss: 0.0000\n",
      "Epoch 3440/4000, Loss: 0.0000\n",
      "Epoch 3450/4000, Loss: 0.0000\n",
      "Epoch 3460/4000, Loss: 0.0000\n",
      "Epoch 3470/4000, Loss: 0.0000\n",
      "Epoch 3480/4000, Loss: 0.0000\n",
      "Epoch 3490/4000, Loss: 0.0000\n",
      "Epoch 3500/4000, Loss: 0.0000\n",
      "Epoch 3510/4000, Loss: 0.0000\n",
      "Epoch 3520/4000, Loss: 0.0000\n",
      "Epoch 3530/4000, Loss: 0.0000\n",
      "Epoch 3540/4000, Loss: 0.0000\n",
      "Epoch 3550/4000, Loss: 0.0000\n",
      "Epoch 3560/4000, Loss: 0.0000\n",
      "Epoch 3570/4000, Loss: 0.0000\n",
      "Epoch 3580/4000, Loss: 0.0000\n",
      "Epoch 3590/4000, Loss: 0.0000\n",
      "Epoch 3600/4000, Loss: 0.0000\n",
      "Epoch 3610/4000, Loss: 0.0000\n",
      "Epoch 3620/4000, Loss: 0.0000\n",
      "Epoch 3630/4000, Loss: 0.0000\n",
      "Epoch 3640/4000, Loss: 0.0000\n",
      "Epoch 3650/4000, Loss: 0.0000\n",
      "Epoch 3660/4000, Loss: 0.0000\n",
      "Epoch 3670/4000, Loss: 0.0000\n",
      "Epoch 3680/4000, Loss: 0.0000\n",
      "Epoch 3690/4000, Loss: 0.0000\n",
      "Epoch 3700/4000, Loss: 0.0000\n",
      "Epoch 3710/4000, Loss: 0.0000\n",
      "Epoch 3720/4000, Loss: 0.0000\n",
      "Epoch 3730/4000, Loss: 0.0000\n",
      "Epoch 3740/4000, Loss: 0.0000\n",
      "Epoch 3750/4000, Loss: 0.0000\n",
      "Epoch 3760/4000, Loss: 0.0000\n",
      "Epoch 3770/4000, Loss: 0.0000\n",
      "Epoch 3780/4000, Loss: 0.0000\n",
      "Epoch 3790/4000, Loss: 0.0000\n",
      "Epoch 3800/4000, Loss: 0.0000\n",
      "Epoch 3810/4000, Loss: 0.0000\n",
      "Epoch 3820/4000, Loss: 0.0000\n",
      "Epoch 3830/4000, Loss: 0.0000\n",
      "Epoch 3840/4000, Loss: 0.0000\n",
      "Epoch 3850/4000, Loss: 0.0000\n",
      "Epoch 3860/4000, Loss: 0.0000\n",
      "Epoch 3870/4000, Loss: 0.0000\n",
      "Epoch 3880/4000, Loss: 0.0000\n",
      "Epoch 3890/4000, Loss: 0.0000\n",
      "Epoch 3900/4000, Loss: 0.0000\n",
      "Epoch 3910/4000, Loss: 0.0000\n",
      "Epoch 3920/4000, Loss: 0.0000\n",
      "Epoch 3930/4000, Loss: 0.0000\n",
      "Epoch 3940/4000, Loss: 0.0000\n",
      "Epoch 3950/4000, Loss: 0.0000\n",
      "Epoch 3960/4000, Loss: 0.0000\n",
      "Epoch 3970/4000, Loss: 0.0000\n",
      "Epoch 3980/4000, Loss: 0.0000\n",
      "Epoch 3990/4000, Loss: 0.0000\n",
      "Epoch 4000/4000, Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "### training loop\n",
    "import subprocess\n",
    "subprocess.run([\"sudo\",\"cpupower\",\"frequency-set\",\"-u\",\"6.0GHz\"])\n",
    "epoch=4000\n",
    "for e in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "    outputs=model_fun1(x)\n",
    "    loss=criterion(outputs,y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (e+1)%10==0:\n",
    "       print(f\"Epoch {e+1}/4000, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e45f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env-3-12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
